# Enem Crawler

Um web crawler robusto desenvolvido em Python utilizando Selenium para baixar provas e gabaritos de ediÃ§Ãµes anteriores do Exame Nacional do Ensino MÃ©dio (ENEM) diretamente do portal do INEP.

## ğŸ¯ Objetivos do Projeto

O principal objetivo deste projeto Ã© automatizar o processo de download das provas e gabaritos do ENEM para fins de estudo, anÃ¡lise ou arquivamento. O crawler foi projetado para:

- **Extrair provas e gabaritos de forma dinÃ¢mica:** Identificar automaticamente os anos disponÃ­veis na pÃ¡gina do INEP, garantindo que novas ediÃ§Ãµes sejam incluÃ­das sem a necessidade de atualizaÃ§Ã£o do cÃ³digo.
- **Baixar provas e gabaritos especÃ­ficos:** Focar na coleta das provas e gabaritos do "Caderno Azul" para o Dia 1 e Dia 2 da AplicaÃ§Ã£o Regular, e, quando disponÃ­veis, das provas e gabaritos do "Caderno Azul" para o Dia 1 e Dia 2 da ReaplicaÃ§Ã£o/PPL, juntamente com o tema da redaÃ§Ã£o de ReaplicaÃ§Ã£o/PPL.
- **Organizar os arquivos baixados:** Salvar os documentos em uma estrutura de diretÃ³rios organizada por ano (`data/{ano}/`).

## ğŸ’ª Robustez e SeguranÃ§a (Anti-DetecÃ§Ã£o de Bots)

Este crawler foi construÃ­do com foco em robustez e na minimizaÃ§Ã£o da detecÃ§Ã£o por mecanismos anti-bot:

- **Atrasos AleatÃ³rios:** Todas as interaÃ§Ãµes significativas (navegaÃ§Ã£o, cliques em abas, downloads) sÃ£o intercaladas com atrasos aleatÃ³rios. Isso simula um comportamento humano mais natural, evitando um padrÃ£o de requisiÃ§Ãµes fixo e repetitivo.
- **Modo Headless com User-Agent:** O Selenium Ã© configurado para rodar em modo headless (sem interface grÃ¡fica), o que Ã© eficiente para automaÃ§Ã£o em segundo plano. AlÃ©m disso, um `User-Agent` de navegador real Ã© definido para que as requisiÃ§Ãµes nÃ£o sejam facilmente identificadas como vindas de um bot.
- **Seletores Resilientes:** A identificaÃ§Ã£o dos elementos HTML na pÃ¡gina (abas de anos, links de download) Ã© feita utilizando seletores CSS e XPath que priorizam atributos Ãºnicos (`data-id`) e o texto visÃ­vel dos elementos (`contains(text(), '...')`). Isso torna o crawler menos vulnerÃ¡vel a pequenas alteraÃ§Ãµes no layout da pÃ¡gina que poderiam quebrar seletores baseados em ordem ou classes genÃ©ricas.
- **Tratamento de ExceÃ§Ãµes:** O cÃ³digo incorpora `try-except` em todas as etapas crÃ­ticas para lidar com erros de rede, elementos nÃ£o encontrados, tempos limite de carregamento da pÃ¡gina ou outras anomalias. Isso impede que o crawler pare abruptamente e permite que ele tente se recuperar ou continue o processamento para os prÃ³ximos itens.

## âš™ï¸ Boas PrÃ¡ticas de ProgramaÃ§Ã£o

O projeto adere a princÃ­pios de boas prÃ¡ticas de programaÃ§Ã£o para garantir um cÃ³digo limpo, legÃ­vel e de fÃ¡cil manutenÃ§Ã£o:

- **ModularizaÃ§Ã£o com FunÃ§Ãµes:** O cÃ³digo Ã© dividido em funÃ§Ãµes pequenas e com responsabilidades bem definidas. Cada funÃ§Ã£o tem um Ãºnico propÃ³sito claro (ex: `iniciar_navegador()`, `obter_anos_disponiveis()`, `baixar_arquivo()`).
- **Logging Detalhado:** Utiliza o mÃ³dulo `logging` do Python para registrar o progresso da execuÃ§Ã£o, avisos (elementos nÃ£o encontrados que nÃ£o sÃ£o crÃ­ticos) e erros (falhas que impedem o avanÃ§o). Isso Ã© essencial para monitorar o crawler e depurar problemas.
- **ConfiguraÃ§Ãµes Externas:** VariÃ¡veis como `BASE_URL`, `OUTPUT_DIR` e `LOG_FILE` sÃ£o definidas no inÃ­cio do script, facilitando a configuraÃ§Ã£o do projeto sem modificar a lÃ³gica principal.
- **ComentÃ¡rios Explicativos:** O cÃ³digo Ã© bem comentado para descrever a lÃ³gica por trÃ¡s de cada funÃ§Ã£o e seÃ§Ã£o.

## ğŸš§ Tratamento de Erros

Um sistema abrangente de tratamento de erros foi implementado:

- **Captura de ExceÃ§Ãµes EspecÃ­ficas:** O cÃ³digo captura exceÃ§Ãµes especÃ­ficas do Selenium (como `TimeoutException`, `NoSuchElementException`, `WebDriverException`) e do mÃ³dulo `requests` (como `requests.exceptions.RequestException`), alÃ©m de exceÃ§Ãµes gerais, permitindo um tratamento adequado para diferentes cenÃ¡rios de falha.
- **Logs Informes:** Erros e avisos sÃ£o registrados no console e em um arquivo de log, fornecendo um histÃ³rico detalhado da execuÃ§Ã£o e dos problemas encontrados.
- **ResiliÃªncia:** Em caso de falha ao processar um ano ou baixar um arquivo especÃ­fico, o crawler tenta continuar para o prÃ³ximo item, evitando a interrupÃ§Ã£o completa do processo.

## ğŸš€ Funcionamento BÃ¡sico e Ordem LÃ³gica de ExecuÃ§Ã£o

O crawler segue uma sequÃªncia lÃ³gica de passos para realizar sua tarefa:

1. **InicializaÃ§Ã£o:**
   - Verifica e cria o diretÃ³rio de saÃ­da principal (`data/`).
   - Configura o sistema de `logging`.
   - Inicia o navegador Chrome em modo headless.
2. **NavegaÃ§Ã£o Inicial:**
   - Acessa a URL base do INEP onde as provas do ENEM estÃ£o listadas.
   - Aguarda um tempo aleatÃ³rio.
3. **IdentificaÃ§Ã£o de Anos:**
   - Analisa a estrutura da pÃ¡gina para identificar dinamicamente todas as abas de anos disponÃ­veis (ex: 2024, 2023, ..., 1998).
   - Os anos sÃ£o processados em ordem decrescente (do mais recente para o mais antigo).
4. **Loop por Ano:** Para cada ano identificado:
   - **Atraso:** Aguarda um tempo aleatÃ³rio antes de interagir.
   - **AtivaÃ§Ã£o da Aba:** Clica no link da aba correspondente ao ano e espera que o conteÃºdo dessa aba seja carregado completamente (verificando o atributo `data-loaded="true"` ou a presenÃ§a de um elemento chave).
   - **ExtraÃ§Ã£o de Links:** Busca e extrai as URLs de download para as provas e gabaritos do "Caderno Azul" (AplicaÃ§Ã£o Regular e ReaplicaÃ§Ã£o/PPL, se houver) e o tema da redaÃ§Ã£o de ReaplicaÃ§Ã£o/PPL.
   - **CriaÃ§Ã£o de DiretÃ³rio:** Cria uma subpasta para o ano (`data/{ano}/`).
   - **Download de Arquivos:** Para cada link de download extraÃ­do:
     - Gera um nome de arquivo descritivo (`ENEM_{ano}_{tipo_prova}.pdf`).
     - Verifica se o arquivo jÃ¡ existe no destino para evitar downloads duplicados.
     - Baixa o arquivo para a pasta do ano.
     - Aguarda um tempo aleatÃ³rio entre os downloads.
5. **FinalizaÃ§Ã£o:**
   - ApÃ³s processar todos os anos, o navegador Ã© encerrado.
   - Uma mensagem de conclusÃ£o Ã© exibida nos logs.

## ğŸ› ï¸ Requisitos

- Python 3.x
- `selenium`
- `requests`
- `webdriver-manager` (opcional, para gerenciar automaticamente o ChromeDriver) ou o `chromedriver` compatÃ­vel com a sua versÃ£o do Chrome instalado no sistema e acessÃ­vel no PATH.

As dependÃªncias sÃ£o listadas em um arquivo `requirements.txt` (sugestÃ£o: crie este arquivo com `pip freeze > requirements.txt` apÃ³s instalar as libs).

## ğŸš€ Como Executar

Para garantir um ambiente limpo e evitar conflitos de dependÃªncias com outros projetos Python, Ã© altamente recomendÃ¡vel utilizar um ambiente virtual (`venv`).

1. **Certifique-se de ter o Google Chrome instalado** em seu sistema, pois o Selenium utilizarÃ¡ o ChromeDriver para interagir com ele.
2. **Crie um ambiente virtual (venv):**

   - Abra seu terminal ou prompt de comando.
   - Navegue atÃ© o diretÃ³rio onde vocÃª salvou o arquivo `download_enem.py`.
   - Execute o seguinte comando para criar o ambiente virtual (um diretÃ³rio chamado `venv` serÃ¡ criado):

     ```bash
     python -m venv venv
     ```

3. **Ative o ambiente virtual:**

   - **No Windows:**

     ```bash
     .\venv\Scripts\activate
     ```

   - **No macOS/Linux:**

     ```bash
     source venv/bin/activate
     ```

     ApÃ³s a ativaÃ§Ã£o, o nome do ambiente virtual (ex: `(venv)`) aparecerÃ¡ no inÃ­cio da sua linha de comando, indicando que ele estÃ¡ ativo.

4. **Instale as dependÃªncias:**

   - Se vocÃª tiver um arquivo `requirements.txt` (recomendado), execute:

     ```bash
     pip install -r requirements.txt
     ```

   - Caso contrÃ¡rio, instale as bibliotecas manualmente:

     ```bash
     pip install selenium requests webdriver-manager
     ```

5. **Baixe o arquivo `download_enem.py`** para o mesmo diretÃ³rio.
6. **Execute o script Python:**

   ```bash
   python download_enem.py
   ```

   O crawler iniciarÃ¡ suas operaÃ§Ãµes. VocÃª verÃ¡ as mensagens de log no terminal, indicando o progresso, avisos e quaisquer erros. Os arquivos baixados serÃ£o armazenados na pasta `data/` criada no mesmo diretÃ³rio de execuÃ§Ã£o do script.

7. **Desativar o ambiente virtual (apÃ³s terminar):**
   Quando vocÃª terminar de usar o crawler, pode desativar o ambiente virtual executando:

   ```bash
   deactivate
   ```

## ğŸ“„ Estrutura de SaÃ­da

Os arquivos baixados serÃ£o organizados da seguinte forma:

```plaintext
data/
â”œâ”€â”€ 2024/
â”‚   â”œâ”€â”€ ENEM_2024_regular_d1_prova_azul.pdf
â”‚   â”œâ”€â”€ ENEM_2024_regular_d1_gabarito_azul.pdf
â”‚   â”œâ”€â”€ ENEM_2024_regular_d2_prova_azul.pdf
â”‚   â”œâ”€â”€ ENEM_2024_regular_d2_gabarito_azul.pdf
â”‚   â”œâ”€â”€ ENEM_2024_reaplicacao_redacao.pdf (se houver)
â”‚   â”œâ”€â”€ ENEM_2024_reaplicacao_d1_prova_azul.pdf (se houver)
â”‚   â”œâ”€â”€ ENEM_2024_reaplicacao_d1_gabarito_azul.pdf (se houver)
â”‚   â”œâ”€â”€ ENEM_2024_reaplicacao_d2_prova_azul.pdf (se houver)
â”‚   â””â”€â”€ ENEM_2024_reaplicacao_d2_gabarito_azul.pdf (se houver)
â”œâ”€â”€ 2023/
â”‚   â””â”€â”€ ...
â””â”€â”€ ...
```

---

**ObservaÃ§Ã£o:** Acesso funcional em Setembro/2025. A confiabilidade do crawler depende da estabilidade da estrutura HTML da pÃ¡gina do INEP. AlteraÃ§Ãµes significativas no layout podem exigir atualizaÃ§Ãµes nos seletores utilizados.
